    
    'LGBMClassifier(colsample_bytree=0.9723552887799483,
               learning_rate=0.07419873126121708, max_depth=8, n_estimators=298,
               nthread=-1, num_class=7, num_leaves=7700, objective='multiclass',
               random_state=42, reg_alpha=0.21928108502014154,
               reg_lambda=0.8046328503330902, subsample=0.8983872887835846,
               verbose=0)'
    Train dataset Absolute Accuracy	: 94.0% 
    Test dataset Absolute Accuracy	: 88.0%
    Train dataset Area Under the Curve (AUC)	: 0.9931373369083882
    Test dataset Area Under the Curve (AUC)	: 0.9644507152401935
    Log Loss	: 0.3279472362780369
    F1 score	: 0.5635145906264859
    
    Classification Report :
               precision    recall  f1-score   support

           0       0.69      0.55      0.61      2789
           1       0.60      0.34      0.44       345
           2       0.68      0.41      0.51       789
           3       0.69      0.42      0.53      1164
           4       0.71      0.36      0.47      1020
           5       0.66      0.33      0.44      1219
           6       0.91      0.98      0.94     35559

    accuracy                           0.88     42885
   macro avg       0.71      0.48      0.56     42885
weighted avg       0.87      0.88      0.87     42885

    Confusion Matrix :
 [[ 1536     8     3     0     1    19  1222]
 [   17   118    14     7     2     8   179]
 [   24     5   323    38    12    12   375]
 [   45     8    19   493    29    10   560]
 [   57     6     9    49   364    54   481]
 [  141     3     1     5    29   404   636]
 [  394    48   103   118    79   109 34708]]
    
    'LGBMClassifier(colsample_bytree=0.9723552887799483,
               learning_rate=0.07419873126121708, max_depth=8, n_estimators=298,
               nthread=-1, num_class=7, num_leaves=7700, objective='multiclass',
               random_state=42, reg_alpha=0.21928108502014154,
               reg_lambda=0.8046328503330902, subsample=0.8983872887835846,
               verbose=0)'
    Train dataset Absolute Accuracy	: 95.0% 
    Test dataset Absolute Accuracy	: 88.0%
    Train dataset Area Under the Curve (AUC)	: 0.9949573314078836
    Test dataset Area Under the Curve (AUC)	: 0.9652558724898072
    Log Loss	: 0.3267058614668092
    F1 score	: 0.5690093631188001
    
    Classification Report :
               precision    recall  f1-score   support

           0       0.68      0.55      0.61      2789
           1       0.68      0.38      0.48       344
           2       0.69      0.41      0.51       789
           3       0.69      0.44      0.53      1164
           4       0.70      0.35      0.47      1021
           5       0.65      0.33      0.44      1219
           6       0.91      0.98      0.94     35559

    accuracy                           0.88     42885
   macro avg       0.71      0.49      0.57     42885
weighted avg       0.87      0.88      0.87     42885

    Confusion Matrix :
 [[ 1527     2     3     3     0    36  1218]
 [   18   129    16     4     2     8   167]
 [   18    11   324    44    10     7   375]
 [   37     1    21   507    31    15   552]
 [   52     4    11    45   356    45   508]
 [  163     3     2     8    23   404   616]
 [  427    40    93   129    87   107 34676]]
    
    'LGBMClassifier(colsample_bytree=0.9723552887799483,
               learning_rate=0.07419873126121708, max_depth=8, n_estimators=298,
               nthread=-1, num_class=7, num_leaves=7700, objective='multiclass',
               random_state=42, reg_alpha=0.21928108502014154,
               reg_lambda=0.8046328503330902, subsample=0.8983872887835846,
               verbose=0)'
    Train dataset Absolute Accuracy	: 95.0% 
    Test dataset Absolute Accuracy	: 88.0%
    Train dataset Area Under the Curve (AUC)	: 0.9945717784932709
    Test dataset Area Under the Curve (AUC)	: 0.9642415931154751
    Log Loss	: 0.32912574514101844
    F1 score	: 0.5623017923996707
    
    Classification Report :
               precision    recall  f1-score   support

           0       0.69      0.53      0.60      2788
           1       0.66      0.38      0.48       345
           2       0.71      0.39      0.50       790
           3       0.70      0.42      0.53      1164
           4       0.70      0.35      0.47      1021
           5       0.62      0.31      0.41      1218
           6       0.91      0.98      0.94     35559

    accuracy                           0.88     42885
   macro avg       0.71      0.48      0.56     42885
weighted avg       0.87      0.88      0.87     42885

    Confusion Matrix :
 [[ 1481     4     2     0     2    36  1263]
 [   19   131    10     9     1     4   171]
 [   36    17   307    43    11    10   366]
 [   25     1    21   494    30    19   574]
 [   59     3    14    35   362    57   491]
 [  147     2     2    11    25   379   652]
 [  388    41    79   117    85   107 34742]]
    